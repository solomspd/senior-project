
@article{fu_n-bref_2020,
	title = {N-Bref : A High-fidelity Decompiler Exploiting Programming Structures},
	url = {https://openreview.net/forum?id=6GkL6qM3LV},
	shorttitle = {N-Bref},
	abstract = {Binary decompilation is a powerful technique for analyzing and understanding software, when source code is unavailable. It is a critical problem in the computer security domain. With the success of...},
	author = {Fu, Cheng and Yang, Kunlin and Chen, Xinyun and Tian, Yuandong and Zhao, Jishen},
	urldate = {2021-09-24},
	date = {2020-09-28},
	langid = {english},
}

@online{noauthor_debin_nodate,
	title = {Debin {\textbar} Proceedings of the 2018 {ACM} {SIGSAC} Conference on Computer and Communications Security},
	url = {https://dl.acm.org/doi/10.1145/3243734.3243866},
	urldate = {2021-09-24},
}

@article{harrand_java_2020,
	title = {Java decompiler diversity and its application to meta-decompilation},
	volume = {168},
	issn = {0164-1212},
	url = {https://www.sciencedirect.com/science/article/pii/S0164121220301151},
	doi = {10.1016/j.jss.2020.110645},
	abstract = {During compilation from Java source code to bytecode, some information is irreversibly lost. In other words, compilation and decompilation of Java code is not symmetric. Consequently, decompilation, which aims at producing source code from bytecode, relies on strategies to reconstruct the information that has been lost. Different Java decompilers use distinct strategies to achieve proper decompilation. In this work, we hypothesize that the diverse ways in which bytecode can be decompiled has a direct impact on the quality of the source code produced by decompilers. In this paper, we assess the strategies of eight Java decompilers with respect to three quality indicators: syntactic correctness, syntactic distortion and semantic equivalence modulo inputs. Our results show that no single modern decompiler is able to correctly handle the variety of bytecode structures coming from real-world programs. The highest ranking decompiler in this study produces syntactically correct, and semantically equivalent code output for 84\%, respectively 78\%, of the classes in our dataset. Our results demonstrate that each decompiler correctly handles a different set of bytecode classes. We propose a new decompiler called Arlecchino that leverages the diversity of existing decompilers. To do so, we merge partial decompilation into a new one based on compilation errors. Arlecchino handles 37.6\% of bytecode classes that were previously handled by no decompiler. We publish the sources of this new bytecode decompiler.},
	pages = {110645},
	journaltitle = {Journal of Systems and Software},
	shortjournal = {Journal of Systems and Software},
	author = {Harrand, Nicolas and Soto-Valero, César and Monperrus, Martin and Baudry, Benoit},
	urldate = {2021-09-24},
	date = {2020-10-01},
	langid = {english},
	keywords = {Decompilation, Java bytecode, Reverse engineering, Source code analysis},
}

@inproceedings{schulte_evolving_2018,
	title = {Evolving Exact Decompilation},
	doi = {10.14722/bar.2018.23008},
	author = {Schulte, Eric and Ruchti, Jason and Noonan, Matt and Ciarletta, David and Loginov, Alexey},
	date = {2018-01-01},
}

@inproceedings{jang_kerberoid_2019,
	location = {New York, {NY}, {USA}},
	title = {Kerberoid: A Practical Android App Decompilation System with Multiple Decompilers},
	isbn = {978-1-4503-6747-9},
	url = {https://doi.org/10.1145/3319535.3363255},
	doi = {10.1145/3319535.3363255},
	series = {{CCS} '19},
	shorttitle = {Kerberoid},
	abstract = {Decompilation is frequently used to analyze binary programs. In Android, however, decompilers all perform differently with varying apps due to their own characteristics. Obviously, there is no universal solution in all conditions. Based on this observation, we present a practical Android app decompilation system (called Kerberoid) that automatically stitches the results from multiple decompilers together to maximize the coverage and the accuracy of decompiled codes. We evaluate the performance of Kerberoid with 151 Android apps in which their corresponding source codes are publicly available. Kerberoid fully recovered all functions for 17\% of the apps tested and gained a similarity score over 50\% for 40\% of the apps tested, increased by 7\% and 9\%, respectively, compared with the best existing decompiler.},
	pages = {2557--2559},
	booktitle = {Proceedings of the 2019 {ACM} {SIGSAC} Conference on Computer and Communications Security},
	publisher = {Association for Computing Machinery},
	author = {Jang, Heejun and Jin, Beomjin and Hyun, Sangwon and Kim, Hyoungshick},
	urldate = {2021-09-24},
	date = {2019-11-06},
	keywords = {android apps, decompilation, mobile security, reverse engineering},
}

@inproceedings{miller_probabilistic_2019,
	title = {Probabilistic Disassembly},
	doi = {10.1109/ICSE.2019.00121},
	abstract = {Disassembling stripped binaries is a prominent challenge for binary analysis, due to the interleaving of code segments and data, and the difficulties of resolving control transfer targets of indirect calls and jumps. As a result, most existing disassemblers have both false positives ({FP}) and false negatives ({FN}). We observe that uncertainty is inevitable in disassembly due to the information loss during compilation and code generation. Therefore, we propose to model such uncertainty using probabilities and propose a novel disassembly technique, which computes a probability for each address in the code space, indicating its likelihood of being a true positive instruction. The probability is computed from a set of features that are reachable to an address, including control flow and data flow features. Our experiments with more than two thousands binaries show that our technique does not have any {FN} and has only 3.7\% {FP}. In comparison, a state-of-the-art superset disassembly technique has 85\% {FP}. A rewriter built on our disassembly can generate binaries that are only half of the size of those by superset disassembly and run 3\% faster. While many widely-used disassemblers such as {IDA} and {BAP} suffer from missing function entries, our experiment also shows that even without any function entry information, our disassembler can still achieve 0 {FN} and 6.8\% {FP}.},
	eventtitle = {2019 {IEEE}/{ACM} 41st International Conference on Software Engineering ({ICSE})},
	pages = {1187--1198},
	booktitle = {2019 {IEEE}/{ACM} 41st International Conference on Software Engineering ({ICSE})},
	author = {Miller, Kenneth and Kwon, Yonghwi and Sun, Yi and Zhang, Zhuo and Zhang, Xiangyu and Lin, Zhiqiang},
	date = {2019-05},
	note = {{ISSN}: 1558-1225},
	keywords = {Computer science, Aggregates, binary, binary rewrite, disassembly, Instruments, probabilistic disassembly, Probabilistic logic, Registers, Runtime, Uncertainty},
}

@article{liang_neutron_2021,
	title = {Neutron: an attention-based neural decompiler},
	volume = {4},
	issn = {2523-3246},
	url = {https://doi.org/10.1186/s42400-021-00070-0},
	doi = {10.1186/s42400-021-00070-0},
	shorttitle = {Neutron},
	abstract = {Decompilation aims to analyze and transform low-level program language ({PL}) codes such as binary code or assembly code to obtain an equivalent high-level {PL}. Decompilation plays a vital role in the cyberspace security fields such as software vulnerability discovery and analysis, malicious code detection and analysis, and software engineering fields such as source code analysis, optimization, and cross-language cross-operating system migration. Unfortunately, the existing decompilers mainly rely on experts to write rules, which leads to bottlenecks such as low scalability, development difficulties, and long cycles. The generated high-level {PL} codes often violate the code writing specifications. Further, their readability is still relatively low. The problems mentioned above hinder the efficiency of advanced applications (e.g., vulnerability discovery) based on decompiled high-level {PL} codes.In this paper, we propose a decompilation approach based on the attention-based neural machine translation ({NMT}) mechanism, which converts low-level {PL} into high-level {PL} while acquiring legibility and keeping functionally similar. To compensate for the information asymmetry between the low-level and high-level {PL}, a translation method based on basic operations of low-level {PL} is designed. This method improves the generalization of the {NMT} model and captures the translation rules between {PLs} more accurately and efficiently. Besides, we implement a neural decompilation framework called Neutron. The evaluation of two practical applications shows that Neutron’s average program accuracy is 96.96\%, which is better than the traditional {NMT} model.},
	pages = {5},
	number = {1},
	journaltitle = {Cybersecurity},
	shortjournal = {Cybersecur},
	author = {Liang, Ruigang and Cao, Ying and Hu, Peiwei and Chen, Kai},
	urldate = {2021-09-28},
	date = {2021-03-05},
	langid = {english},
}

@article{escalada_improving_2021,
	title = {Improving type information inferred by decompilers with supervised machine learning},
	url = {http://arxiv.org/abs/2101.08116},
	abstract = {In software reverse engineering, decompilation is the process of recovering source code from binary files. Decompilers are used when it is necessary to understand or analyze software for which the source code is not available. Although existing decompilers commonly obtain source code with the same behavior as the binaries, that source code is usually hard to interpret and certainly differs from the original code written by the programmer. Massive codebases could be used to build supervised machine learning models aimed at improving existing decompilers. In this article, we build different classification models capable of inferring the high-level type returned by functions, with significantly higher accuracy than existing decompilers. We automatically instrument C source code to allow the association of binary patterns with their corresponding high-level constructs. A dataset is created with a collection of real open-source applications plus a huge number of synthetic programs. Our system is able to predict function return types with a 79.1\% F1-measure, whereas the best decompiler obtains a 30\% F1-measure. Moreover, we document the binary patterns used by our classifier to allow their addition in the implementation of existing decompilers.},
	journaltitle = {{arXiv}:2101.08116 [cs]},
	author = {Escalada, Javier and Scully, Ted and Ortin, Francisco},
	urldate = {2021-09-28},
	date = {2021-02-24},
	eprinttype = {arxiv},
	eprint = {2101.08116},
	keywords = {Computer Science - Machine Learning, Computer Science - Programming Languages, Computer Science - Software Engineering, D.2.3, D.3.4, I.2.6, I.5.1},
}

@article{fu_neural-based_2019,
	title = {A Neural-based Program Decompiler},
	url = {http://arxiv.org/abs/1906.12029},
	abstract = {Reverse engineering of binary executables is a critical problem in the computer security domain. On the one hand, malicious parties may recover interpretable source codes from the software products to gain commercial advantages. On the other hand, binary decompilation can be leveraged for code vulnerability analysis and malware detection. However, efficient binary decompilation is challenging. Conventional decompilers have the following major limitations: (i) they are only applicable to specific source-target language pair, hence incurs undesired development cost for new language tasks; (ii) their output high-level code cannot effectively preserve the correct functionality of the input binary; (iii) their output program does not capture the semantics of the input and the reversed program is hard to interpret. To address the above problems, we propose Coda, the first end-to-end neural-based framework for code decompilation. Coda decomposes the decompilation task into two key phases: First, Coda employs an instruction type-aware encoder and a tree decoder for generating an abstract syntax tree ({AST}) with attention feeding during the code sketch generation stage. Second, Coda then updates the code sketch using an iterative error correction machine guided by an ensembled neural error predictor. By finding a good approximate candidate and then fixing it towards perfect, Coda achieves superior performance compared to baseline approaches. We assess Coda's performance with extensive experiments on various benchmarks. Evaluation results show that Coda achieves an average of 82{\textbackslash}\% program recovery accuracy on unseen binary samples, where the state-of-the-art decompilers yield 0{\textbackslash}\% accuracy. Furthermore, Coda outperforms the sequence-to-sequence model with attention by a margin of 70{\textbackslash}\% program accuracy.},
	journaltitle = {{arXiv}:1906.12029 [cs]},
	author = {Fu, Cheng and Chen, Huili and Liu, Haolan and Chen, Xinyun and Tian, Yuandong and Koushanfar, Farinaz and Zhao, Jishen},
	urldate = {2021-09-28},
	date = {2019-06-27},
	eprinttype = {arxiv},
	eprint = {1906.12029},
	keywords = {Computer Science - Machine Learning, Computer Science - Programming Languages},
}

@inproceedings{katz_using_2018,
	title = {Using recurrent neural networks for decompilation},
	doi = {10.1109/SANER.2018.8330222},
	abstract = {Decompilation, recovering source code from binary, is useful in many situations where it is necessary to analyze or understand software for which source code is not available. Source code is much easier for humans to read than binary code, and there are many tools available to analyze source code. Existing decompilation techniques often generate source code that is difficult for humans to understand because the generated code often does not use the coding idioms that programmers use. Differences from human-written code also reduce the effectiveness of analysis tools on the decompiled source code. To address the problem of differences between decompiled code and human-written code, we present a novel technique for decompiling binary code snippets using a model based on Recurrent Neural Networks. The model learns properties and patterns that occur in source code and uses them to produce decompilation output. We train and evaluate our technique on snippets of binary machine code compiled from C source code. The general approach we outline in this paper is not language-specific and requires little or no domain knowledge of a language and its properties or how a compiler operates, making the approach easily extensible to new languages and constructs. Furthermore, the technique can be extended and applied in situations to which traditional decompilers are not targeted, such as for decompilation of isolated binary snippets; fast, on-demand decompilation; domain-specific learned decompilation; optimizing for readability of decompilation; and recovering control flow constructs, comments, and variable or function names. We show that the translations produced by this technique are often accurate or close and can provide a useful picture of the snippet's behavior.},
	eventtitle = {2018 {IEEE} 25th International Conference on Software Analysis, Evolution and Reengineering ({SANER})},
	pages = {346--356},
	booktitle = {2018 {IEEE} 25th International Conference on Software Analysis, Evolution and Reengineering ({SANER})},
	author = {Katz, Deborah S. and Ruchti, Jason and Schulte, Eric},
	date = {2018-03},
	keywords = {decompilation, Binary codes, Data models, Decoding, deep learning, Natural languages, recurrent neural networks, Recurrent neural networks, Tools, Training, translation},
}

@inproceedings{miller_probabilistic_2019-1,
	title = {Probabilistic Disassembly},
	doi = {10.1109/ICSE.2019.00121},
	abstract = {Disassembling stripped binaries is a prominent challenge for binary analysis, due to the interleaving of code segments and data, and the difficulties of resolving control transfer targets of indirect calls and jumps. As a result, most existing disassemblers have both false positives ({FP}) and false negatives ({FN}). We observe that uncertainty is inevitable in disassembly due to the information loss during compilation and code generation. Therefore, we propose to model such uncertainty using probabilities and propose a novel disassembly technique, which computes a probability for each address in the code space, indicating its likelihood of being a true positive instruction. The probability is computed from a set of features that are reachable to an address, including control flow and data flow features. Our experiments with more than two thousands binaries show that our technique does not have any {FN} and has only 3.7\% {FP}. In comparison, a state-of-the-art superset disassembly technique has 85\% {FP}. A rewriter built on our disassembly can generate binaries that are only half of the size of those by superset disassembly and run 3\% faster. While many widely-used disassemblers such as {IDA} and {BAP} suffer from missing function entries, our experiment also shows that even without any function entry information, our disassembler can still achieve 0 {FN} and 6.8\% {FP}.},
	eventtitle = {2019 {IEEE}/{ACM} 41st International Conference on Software Engineering ({ICSE})},
	pages = {1187--1198},
	booktitle = {2019 {IEEE}/{ACM} 41st International Conference on Software Engineering ({ICSE})},
	author = {Miller, Kenneth and Kwon, Yonghwi and Sun, Yi and Zhang, Zhuo and Zhang, Xiangyu and Lin, Zhiqiang},
	date = {2019-05},
	note = {{ISSN}: 1558-1225},
	keywords = {Computer science, Aggregates, binary, binary rewrite, disassembly, Instruments, probabilistic disassembly, Probabilistic logic, Registers, Runtime, Uncertainty},
}

@inproceedings{naitian_dexfus_2020,
	title = {{DexFus}: An Android Obfuscation Technique Based on Dalvik Bytecode Translation},
	doi = {10.1007/978-981-15-9739-8_32},
	shorttitle = {{DexFus}},
	abstract = {{DexFus} applies obfuscation on translated C code instead of the original Dalvik code, which provides a higher level protection for applications, and is able to protect target applications with reasonable storage and memory overhead and high stability. Cracking and repackaging is a severe threat to Android applications. Obfuscation increases the difficulty of reverse analysis without changing the semantics of the original code. However, current Android obfuscation techniques primarily concentrate on Dalvik bytecode obfuscation, as Dalvik bytecode contains much semantic information, obfuscation does not hinder the attacker much. We propose a new technique named {DexFus} for protecting Android code based on Dalvik bytecode translation. {DexFus} applies obfuscation on translated C code instead of the original Dalvik code, which provides a higher level protection for applications. A prototype deployment on the Android platform demonstrates that {DexFus} is able to protect target applications with reasonable storage and memory overhead and high stability.},
	author = {Naitian, Hu and Xingkong, Ma and Lin, Fuqiang and Bo, Liu and Tong, Lu},
	date = {2020},
}

@article{li_adabot_2019,
	title = {Adabot: Fault-Tolerant Java Decompiler},
	url = {http://arxiv.org/abs/1908.06748},
	shorttitle = {Adabot},
	abstract = {Reverse Engineering({RE}) has been a fundamental task in software engineering. However, most of the traditional Java reverse engineering tools are strictly rule defined, thus are not fault-tolerant, which pose serious problem when noise and interference were introduced into the system. In this paper, we view reverse engineering as a statistical machine translation task instead of rule-based task, and propose a fault-tolerant Java decompiler based on machine translation models. Our model is based on attention-based Neural Machine Translation ({NMT}) and Transformer architectures. First, we measure the translation quality on both the redundant and purified datasets. Next, we evaluate the fault-tolerance(anti-noise ability) of our framework on test sets with different unit error probability ({UEP}). In addition, we compare the suitability of different word segmentation algorithms for decompilation task. Experimental results demonstrate that our model is more robust and fault-tolerant compared to traditional Abstract Syntax Tree ({AST}) based decompilers. Specifically, in terms of {BLEU}-4 and Word Error Rate ({WER}), our performance has reached 94.50\% and 2.65\% on the redundant test set; 92.30\% and 3.48\% on the purified test set.},
	journaltitle = {{arXiv}:1908.06748 [cs]},
	author = {Li, Zhiming and Wu, Qing and Qian, Kun},
	urldate = {2021-09-28},
	date = {2019-10-15},
	eprinttype = {arxiv},
	eprint = {1908.06748},
	keywords = {Computer Science - Computation and Language, Computer Science - Software Engineering},
}